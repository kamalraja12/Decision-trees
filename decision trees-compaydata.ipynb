import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.tree import  DecisionTreeClassifier
from sklearn import tree
from sklearn.metrics import classification_report
from sklearn import preprocessing

data = pd.read_csv('D:\ExcelR\Assignments\decision trees\Company_Data.csv')
data


data.shape
data.info()

sns.pairplot(data)
plt.figure(figsize=(20,10))
sns.heatmap(data.corr(),annot=True)


label_encoder = preprocessing.LabelEncoder()
data['ShelveLoc']= label_encoder.fit_transform(data['ShelveLoc'])
data['Urban']= label_encoder.fit_transform(data['Urban'])
data['US']= label_encoder.fit_transform(data['US'])

data


x=data.iloc[:,0:6]
y=data['ShelveLoc']

x
y

data['ShelveLoc'].unique() 
data.ShelveLoc.value_counts()
colnames = list(data.columns)
colnames

x_train, x_test,y_train,y_test = train_test_split(x,y, test_size=0.2,random_state=40)          # Splitting data into training and testing data set


# #Building Decision Tree Classifier using Entropy Criteria
model = DecisionTreeClassifier(criterion = 'entropy',max_depth=3)
model.fit(x_train,y_train) 
tree.plot_tree(model);             #PLot the decision tree

fn=['Sales',	'CompPrice', 	'Income',	'Advertising',	'Population',	'Price']
cn=['Bad', 'Good', 'Medium']
fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=300)
tree.plot_tree(model,
               feature_names = fn, 
               class_names=cn,
               filled = True);

model.feature_importances_ 

feature_imp = pd.Series(model.feature_importances_,index=fn).sort_values(ascending=False) 
feature_imp

sns.barplot(x=feature_imp, y=feature_imp.index)
plt.xlabel('Feature Importance Score')
plt.ylabel('Features')
plt.title("Visualizing Important Features")
plt.show()

#Predicting on test data
preds = model.predict(x_test)                  # predicting on test data set 
pd.Series(preds).value_counts()                # getting the count of each category 

preds

pd.crosstab(y_test,preds)  # getting the 2 way table to understand the correct and wrong predictions


np.mean(preds==y_test)          #accuracy


# #Building Decision Tree Classifier (CART) using Gini Criteria
# 
model_gini = DecisionTreeClassifier(criterion='gini', max_depth=3)
model_gini.fit(x_train, y_train) 
pred=model.predict(x_test)
np.mean(preds==y_test)                       #Prediction and computing the accuracy 

model.feature_importances_ 


# #Decision Tree Regression

from sklearn.tree import DecisionTreeRegressor 

array = data.values
X = array[:,0:6]
y = array[:,3]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1) 

model = DecisionTreeRegressor()
model.fit(X_train, y_train) 
model.score(X_test,y_test)           #accuracy
